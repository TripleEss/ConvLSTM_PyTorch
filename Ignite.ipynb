{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yvxg6ChLp90c"
   },
   "source": [
    "## Install module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HymaOk0pU1B"
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-ignite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JCLGCoXp6z7"
   },
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vmDOK5UGqV-S"
   },
   "outputs": [],
   "source": [
    "!curl -o mnist_test_seq.npy http://www.cs.toronto.edu/~nitish/unsupervised_video/mnist_test_seq.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ag1DCystNRiP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MovingMnistDataset(Dataset):\n",
    "    def __init__(self, path=\"./mnist_test_seq.npy\", phase_train=True):\n",
    "        self.data = np.load(path)\n",
    "        # (t, N, H, W) -> (N, t, C, H, W)\n",
    "        self.data = self.data.transpose(1, 0, 2, 3)[:, :, None, ...]\n",
    "        if phase_train:\n",
    "            self.data = self.data[:1000]\n",
    "        else:\n",
    "            self.data = self.data[9000:]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return (self.data[i, :10, ...] / 255).astype(np.float32), (self.data[i, 10:, ...]/255).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1LmgQrAqB9p"
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sFO0VQGiNXHj"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright (c) 2020 Masafumi Abeta. All Rights Reserved.\n",
    "Released under the MIT license\n",
    "\"\"\"\n",
    "import math\n",
    "import uuid\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair\n",
    "\n",
    "\n",
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels,\n",
    "                 kernel_size, stride=1, image_size=None):\n",
    "        \"\"\"ConvLSTM cell.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_channels: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: int or (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        stride: int or (int, int)\n",
    "            Stride of the convolution.\n",
    "        image_size: (int, int)\n",
    "            Shape of image.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "\n",
    "        # No bias for hidden, since bias is included in observation convolution\n",
    "        # Pad the hidden layer so that the input and output sizes are equal\n",
    "        self.Wxi = Conv2dStaticSamePadding(\n",
    "            self.in_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size)\n",
    "        self.Whi = Conv2dStaticSamePadding(\n",
    "            self.hidden_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size, bias=False)\n",
    "        self.Wxf = Conv2dStaticSamePadding(\n",
    "            self.in_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size)\n",
    "        self.Whf = Conv2dStaticSamePadding(\n",
    "            self.hidden_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size, bias=False)\n",
    "        self.Wxg = Conv2dStaticSamePadding(\n",
    "            self.in_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size)\n",
    "        self.Whg = Conv2dStaticSamePadding(\n",
    "            self.hidden_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size, bias=False)\n",
    "        self.Wxo = Conv2dStaticSamePadding(\n",
    "            self.in_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size)\n",
    "        self.Who = Conv2dStaticSamePadding(\n",
    "            self.hidden_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=image_size, bias=False)\n",
    "\n",
    "    def forward(self, x, hidden_state):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: torch.Tensor\n",
    "            4-D Tensor of shape (b, c, h, w).\n",
    "        hs: tuple\n",
    "            Previous hidden state of shape (h_0, c_0).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            h_next, c_next\n",
    "        \"\"\"\n",
    "\n",
    "        h_prev, c_prev = hidden_state\n",
    "        i = torch.sigmoid(self.Wxi(x) + self.Whi(h_prev))\n",
    "        f = torch.sigmoid(self.Wxf(x) + self.Whf(h_prev))\n",
    "        o = torch.sigmoid(self.Wxo(x) + self.Who(h_prev))\n",
    "        g = torch.tanh(self.Wxg(x) + self.Whg(h_prev))\n",
    "\n",
    "        c_next = f * c_prev + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "\n",
    "class ConvLSTM(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels,\n",
    "                 kernel_size, stride=1, image_size=None):\n",
    "        \"\"\"ConvLSTM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_channels: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: int or (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        stride: int or (int, int)\n",
    "            Stride of the convolution.\n",
    "        image_size: (int, int)\n",
    "            Shape of image.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.kernel_size = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.lstm_cell = ConvLSTMCell(\n",
    "            self.in_channels, self.hidden_channels, self.kernel_size, self.stride, image_size=self.image_size)\n",
    "\n",
    "    def forward(self, xs, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        xs: torch.Tensor\n",
    "            5-D Tensor of shape (b, t, c, h, w).\n",
    "        hs: list\n",
    "            Previous hidden state of shape (h_0, c_0).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            last_state_list, layer_output\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, sequence_length, _, height, width = xs.size()\n",
    "\n",
    "        if hidden_state is None:\n",
    "            hidden_state = (torch.zeros(batch_size, self.hidden_channels, height, width, device=xs.device),\n",
    "                            torch.zeros(batch_size, self.hidden_channels, height, width, device=xs.device))\n",
    "\n",
    "        output_list = []\n",
    "        for t in range(sequence_length):\n",
    "            hidden_state = self.lstm_cell(xs[:, t, ...], hidden_state)\n",
    "            h, _ = hidden_state\n",
    "            output_list.append(h)\n",
    "\n",
    "        output = torch.stack(output_list, dim=1)\n",
    "\n",
    "        return output, hidden_state\n",
    "\n",
    "\n",
    "class Conv2dStaticSamePadding(nn.Conv2d):\n",
    "    \"\"\"2D Convolutions like TensorFlow's 'SAME' mode, with the given input image size.\n",
    "       The padding mudule is calculated in construction function, then used in forward.\n",
    "\n",
    "        # Copyright: lukemelas (github username)\n",
    "        # Released under the MIT License <https://github.com/lukemelas/EfficientNet-PyTorch/blob/master/LICENSE>\n",
    "        # <https://github.com/lukemelas/EfficientNet-PyTorch/blob/4d63a1f77eb51a58d6807a384dda076808ec02c0/efficientnet_pytorch/utils.py>\n",
    "    \"\"\"\n",
    "\n",
    "    # With the same calculation as Conv2dDynamicSamePadding\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, image_size=None, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, **kwargs)\n",
    "        self.stride = self.stride if len(self.stride) == 2 else [\n",
    "            self.stride[0]] * 2\n",
    "\n",
    "        # Calculate padding based on image size and save it\n",
    "        assert image_size is not None\n",
    "        ih, iw = (image_size, image_size) if isinstance(\n",
    "            image_size, int) else image_size\n",
    "        kh, kw = self.weight.size()[-2:]\n",
    "        sh, sw = self.stride\n",
    "        oh, ow = math.ceil(ih / sh), math.ceil(iw / sw)\n",
    "        pad_h = max((oh - 1) * self.stride[0] +\n",
    "                    (kh - 1) * self.dilation[0] + 1 - ih, 0)\n",
    "        pad_w = max((ow - 1) * self.stride[1] +\n",
    "                    (kw - 1) * self.dilation[1] + 1 - iw, 0)\n",
    "        if pad_h > 0 or pad_w > 0:\n",
    "            self.static_padding = nn.ZeroPad2d(\n",
    "                (pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2))\n",
    "        else:\n",
    "            self.static_padding = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.static_padding(x)\n",
    "        x = F.conv2d(x, self.weight, self.bias, self.stride,\n",
    "                     self.padding, self.dilation, self.groups)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mcK3z4y4NXJ1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ConvLSTMEncoderPredictor(nn.Module):\n",
    "    def __init__(self, image_size):\n",
    "        \"\"\"ConvLSTM Encoder Predictor.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_size: (int, int)\n",
    "            Shape of image.\n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_1 = ConvLSTM(\n",
    "            in_channels=1, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "        self.encoder_2 = ConvLSTM(\n",
    "            in_channels=64, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "        self.encoder_3 = ConvLSTM(\n",
    "            in_channels=64, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "\n",
    "        self.predictor_1 = ConvLSTM(\n",
    "            in_channels=64, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "        self.predictor_2 = ConvLSTM(\n",
    "            in_channels=64, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "        self.predictor_3 = ConvLSTM(\n",
    "            in_channels=64, hidden_channels=64, kernel_size=3, stride=1, image_size=image_size)\n",
    "\n",
    "        self.conv2d = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, hidden_state_1 = self.encoder_1(x)\n",
    "        x, hidden_state_2 = self.encoder_2(x)\n",
    "        x, hidden_state_3 = self.encoder_3(x)\n",
    "\n",
    "        x, _ = self.predictor_1(torch.zeros_like(x), hidden_state_1)\n",
    "        x, _ = self.predictor_2(x, hidden_state_2)\n",
    "        x, _ = self.predictor_3(x, hidden_state_3)\n",
    "\n",
    "        seq_output = []\n",
    "        for t in range(x.shape[1]):\n",
    "            tmp = self.conv2d(x[:, t, :, :, :])\n",
    "            seq_output.append(tmp)\n",
    "        output = torch.stack(seq_output, 1)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "olcbupYCqJ5q"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ypX9qnH2cRjv"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "import catalyst\n",
    "from catalyst.callbacks.checkpoint import CheckpointCallback\n",
    "from catalyst.callbacks.misc import EarlyStoppingCallback\n",
    "from catalyst.dl import SupervisedRunner\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    if args is None:\n",
    "        args = argument_paser()\n",
    "\n",
    "    # Set experiment id\n",
    "    exp_id = str(uuid.uuid4())[:8] if args.exp_id is None else args.exp_id\n",
    "    print(f'Experiment Id: {exp_id}', flush=True)\n",
    "\n",
    "    # Fix seed\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # Config gpu\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    # Prepare data\n",
    "    dataset = MovingMnistDataset()\n",
    "    train_index, valid_index = train_test_split(\n",
    "        range(len(dataset)), test_size=0.3)\n",
    "    train_loader = DataLoader(\n",
    "        Subset(dataset, train_index), batch_size=args.batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(\n",
    "        Subset(dataset, valid_index), batch_size=args.test_batch_size, shuffle=False)\n",
    "    loaders = {\"train\": train_loader, \"valid\": valid_loader}\n",
    "\n",
    "    model = ConvLSTMEncoderPredictor(image_size=(64, 64)).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    runner = SupervisedRunner(device=catalyst.utils.get_device())\n",
    "    runner.train(\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=None,\n",
    "        loaders=loaders,\n",
    "        # model will be saved to {logdir}/checkpoints\n",
    "        logdir=os.path.join(args.log_dir, exp_id),\n",
    "        callbacks=[CheckpointCallback(save_n_best=args.n_saved),\n",
    "                   EarlyStoppingCallback(patience=args.es_patience,\n",
    "                                         metric=\"loss\",\n",
    "                                         minimize=True,)],\n",
    "        num_epochs=args.epochs,\n",
    "        main_metric=\"loss\",\n",
    "        minimize_metric=True,\n",
    "        fp16=None,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "\n",
    "def argument_paser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=16, metavar='N',\n",
    "                        help='input batch size for training (default: 16)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=16,\n",
    "                        metavar='N',\n",
    "                        help='input batch size for testing (default: 16)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    # parser.add_argument('--save-model-path', type=str, default='./checkpoints',\n",
    "    #                     help='For Saving the current Model (default: ./checkpoints)')\n",
    "    parser.add_argument('--n-saved', type=int, default=1,\n",
    "                        help='For Saving the current Model (default: 1)')\n",
    "    # parser.add_argument('--log-interval', type=int, default=0,\n",
    "    #                     help='logging interval (default: 0)')\n",
    "    parser.add_argument('--log-dir', type=str, default='./logs',\n",
    "                        help='path to snapshot file (default: ./logs)')\n",
    "    parser.add_argument('--es-patience', type=int, default=10,\n",
    "                        help='Early stop patience (default: 10)')\n",
    "    parser.add_argument('--exp-id', type=str, default=None,\n",
    "                        help='experiment id')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JeKFoO9LdfnU"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.data.dataset import Subset\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from ignite.contrib.handlers import ProgressBar\n",
    "from ignite.engine import (Events, create_supervised_evaluator,\n",
    "                           create_supervised_trainer)\n",
    "from ignite.handlers import EarlyStopping, ModelCheckpoint, Timer\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "\n",
    "\n",
    "\n",
    "def write_metrics(metrics, writer, timer, mode: str, epoch: int):\n",
    "    \"\"\"print metrics & write metrics to log\"\"\"\n",
    "    avg_loss = metrics['mse']\n",
    "    print(f\"{mode} Results - Epoch: {epoch} -- Avg loss: {avg_loss:.5f} -- Elapsed time: {timer.value():.2f}\")\n",
    "    if writer is not None:\n",
    "        writer.add_scalar(f\"{mode}/avg_loss\", avg_loss, epoch)\n",
    "\n",
    "\n",
    "def score_function(engine):\n",
    "    val_loss = engine.state.metrics['mse']\n",
    "    return - val_loss\n",
    "\n",
    "\n",
    "def _epoch(engine, event_name):\n",
    "    return engine.state.epoch\n",
    "\n",
    "\n",
    "def run(exp_id, epochs, model, criterion, optimizer, scheduler,\n",
    "        train_loader, valid_loader, device, writer, log_interval,\n",
    "        n_saved, save_dir, es_patience):\n",
    "\n",
    "    # check parameters\n",
    "    assert exp_id is not None\n",
    "    assert model is not None\n",
    "    assert criterion is not None\n",
    "    assert optimizer is not None\n",
    "    assert train_loader is not None\n",
    "    assert valid_loader is not None\n",
    "    assert device is not None\n",
    "    assert save_dir is not None\n",
    "\n",
    "    trainer = create_supervised_trainer(\n",
    "        model, optimizer, criterion, device=device)\n",
    "    evaluator = create_supervised_evaluator(\n",
    "        model,\n",
    "        metrics={'mse': Loss(criterion)},\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    # # Timer\n",
    "    timer = Timer(average=False)\n",
    "    timer.attach(trainer,\n",
    "                 start=Events.EPOCH_STARTED,\n",
    "                 pause=Events.EPOCH_COMPLETED,\n",
    "                 resume=Events.EPOCH_STARTED,\n",
    "                 step=Events.EPOCH_COMPLETED)\n",
    "\n",
    "    RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
    "\n",
    "    pbar = ProgressBar(persist=True)\n",
    "    pbar.attach(trainer, metric_names='all')\n",
    "\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        if log_interval > 0:\n",
    "            i = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "            if i % log_interval == 0:\n",
    "                print(f\"Epoch[{engine.state.epoch}] -- Iteration[{i}/{len(train_loader)}] -- \"\n",
    "                      f\"Loss: {engine.state.output:.5f} -- Elapsed time: {timer.value():.2f}\")\n",
    "                if writer is not None:\n",
    "                    writer.add_scalar(\"training/loss\", engine.state.output,\n",
    "                                      engine.state.iteration)\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        evaluator.run(train_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        write_metrics(metrics, writer, timer, 'Training', engine.state.epoch)\n",
    "\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_validation_results(engine):\n",
    "        evaluator.run(valid_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        write_metrics(metrics, writer, timer, 'Validation', engine.state.epoch)\n",
    "\n",
    "        pbar.n = pbar.last_print_n = 0\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def save_optimizer(engine):\n",
    "        # Save optimizer\n",
    "        optimizer_file_name = os.path.join(\n",
    "            save_dir, exp_id, 'optimizer.pth')\n",
    "        torch.save(optimizer.state_dict(), optimizer_file_name)\n",
    "        print(\"Save optimizer :\", optimizer_file_name)\n",
    "\n",
    "        # Save scheduler\n",
    "        if scheduler is not None:\n",
    "            scheduler_file_name = os.path.join(\n",
    "                save_dir, exp_id, 'scheduler.pth')\n",
    "            torch.save(scheduler.state_dict(), scheduler_file_name)\n",
    "            print(\"Save optimizer :\", scheduler_file_name)\n",
    "\n",
    "    # # Checkpoint setting\n",
    "    # {save_dir}/{exp_id}/best_mymodel_{engine.state.epoch}\n",
    "    # n_saved 個までモデルを保持する\n",
    "    handler = ModelCheckpoint(dirname=f'{save_dir}/{exp_id}', filename_prefix='best',\n",
    "                              n_saved=n_saved, create_dir=True, global_step_transform=_epoch)\n",
    "    trainer.add_event_handler(Events.EPOCH_COMPLETED,\n",
    "                              handler, {'mymodel': model})\n",
    "\n",
    "    # # Early stopping\n",
    "    handler = EarlyStopping(\n",
    "        patience=es_patience, score_function=score_function, trainer=trainer)\n",
    "    # Note: the handler is attached to an *Evaluator* (runs one epoch on validation dataset)\n",
    "    evaluator.add_event_handler(Events.COMPLETED, handler)\n",
    "\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "\n",
    "\n",
    "def argument_paser():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=16, metavar='N',\n",
    "                        help='input batch size for training (default: 16)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=16,\n",
    "                        metavar='N',\n",
    "                        help='input batch size for testing (default: 16)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--save-model-path', type=str, default='./checkpoints',\n",
    "                        help='For Saving the current Model (default: ./checkpoints)')\n",
    "    parser.add_argument('--n-saved', type=int, default=1,\n",
    "                        help='For Saving the current Model (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=0,\n",
    "                        help='logging interval (default: 0)')\n",
    "    parser.add_argument('--log-dir', type=str, default='./logs',\n",
    "                        help='path to snapshot file (default: ./logs)')\n",
    "    parser.add_argument('--es-patience', type=int, default=10,\n",
    "                        help='Early stop patience (default: 10)')\n",
    "    parser.add_argument('--exp-id', type=str, default=None,\n",
    "                        help='experiment id')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def main(args=None):\n",
    "    if args is None:\n",
    "        args = argument_paser()\n",
    "\n",
    "    # Set experiment id\n",
    "    exp_id = str(uuid.uuid4())[:8] if args.exp_id is None else args.exp_id\n",
    "    print(f'Experiment Id: {exp_id}', flush=True)\n",
    "\n",
    "    # Fix seed\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    # Set logger\n",
    "    log_writer = SummaryWriter(log_dir=os.path.join(\n",
    "        args.log_dir, exp_id)) if args.log_dir is not None else None\n",
    "\n",
    "    # Prepare data\n",
    "    dataset = MovingMnistDataset()\n",
    "    train_index, valid_index = train_test_split(\n",
    "        range(len(dataset)), test_size=0.3)\n",
    "    train_loader = DataLoader(\n",
    "        Subset(dataset, train_index), batch_size=args.batch_size, shuffle=True)\n",
    "    valid_loader = DataLoader(\n",
    "        Subset(dataset, valid_index), batch_size=args.test_batch_size, shuffle=False)\n",
    "\n",
    "    # Prepare model\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = ConvLSTMEncoderPredictor(image_size=(64, 64)).to(device)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    run(\n",
    "        exp_id=exp_id,\n",
    "        epochs=args.epochs,\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=None,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        device=device,\n",
    "        writer=log_writer,\n",
    "        log_interval=args.log_interval,\n",
    "        n_saved=args.n_saved,\n",
    "        save_dir=args.save_model_path,\n",
    "        es_patience=args.es_patience\n",
    "    )\n",
    "\n",
    "    log_writer.close()\n",
    "\n",
    "    return exp_id, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "41RtfNN_NiCX"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "parser.add_argument('--batch-size', type=int, default=4, metavar='N',\n",
    "                    help='input batch size for training (default: 16)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=4,\n",
    "                    metavar='N',\n",
    "                    help='input batch size for testing (default: 16)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                    help='learning rate (default: 0.01)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--save-model-path', type=str, default='./checkpoints',\n",
    "                    help='For Saving the current Model (default: ./checkpoints)')\n",
    "parser.add_argument('--n-saved', type=int, default=1,\n",
    "                    help='For Saving the current Model (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=0,\n",
    "                    help='logging interval (default: 0)')\n",
    "parser.add_argument('--log-dir', type=str, default='./logs',\n",
    "                    help='path to snapshot file (default: ./logs)')\n",
    "parser.add_argument('--es-patience', type=int, default=10,\n",
    "                    help='Early stop patience (default: 10)')\n",
    "parser.add_argument('--exp-id', type=str, default=None,\n",
    "                    help='experiment id')\n",
    "args = parser.parse_args(args=['--epochs', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_OtPqSCvecYt"
   },
   "outputs": [],
   "source": [
    "exp_id, model = main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E2EI4afevpFZ"
   },
   "outputs": [],
   "source": [
    "!cat ./logs/2528be32/log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKBDg7uzWAMx"
   },
   "outputs": [],
   "source": [
    "import gc; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O5lMeBUUuvGo"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7jYfJZ76qcgb"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9uRbANKC4g-"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "def inference(args=None):\n",
    "    if args is None:\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--model-path', '-m', type=str, default=None)\n",
    "        parser.add_argument('--id', '-i', type=int, default=0)\n",
    "        args = parser.parse_args()\n",
    "    \n",
    "\n",
    "    test = MovingMnistDataset(phase_train=False)\n",
    "\n",
    "    model = ConvLSTMEncoderPredictor(image_size=(64, 64))\n",
    "\n",
    "    if args.model_path is not None:\n",
    "        print(\"loading model from \" + args.model_path)\n",
    "        model.load_state_dict(torch.load(args.model_path))\n",
    "\n",
    "    data, target = test[args.id]\n",
    "\n",
    "    data = np.expand_dims(data, 0)\n",
    "    target = np.expand_dims(target, 0)\n",
    "\n",
    "    data = torch.from_numpy(data.astype(np.float32)).clone()\n",
    "    res = model(data).to('cpu').detach().numpy().copy()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7YuPgsWac74"
   },
   "outputs": [],
   "source": [
    "!ls ./checkpoints/18d8b87a/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RzXy4ujlrCeg"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--model-path', '-m', type=str, default=None)\n",
    "parser.add_argument('--id', '-i', type=int, default=0)\n",
    "args = parser.parse_args(args=['--model-path', './checkpoints/18d8b87a/best_mymodel_3.pt', '--id', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nx-hJC5BrM4Z"
   },
   "outputs": [],
   "source": [
    "result = inference(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "brAeUc-2rUQc"
   },
   "outputs": [],
   "source": [
    "result = result.reshape(result.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "slqpzjK-alQi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "\n",
    "def f(k):\n",
    "    plt.imshow(result[k][0], 'gray')\n",
    "    plt.show()\n",
    "\n",
    "interact(f, k=(0,9,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bvf0XdwUa8UU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Ignite.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
